{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "805fef1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Sat Oct 27 17:41:20 2018\n",
    "@author: Mohammad Wasil Saleem.\n",
    "\"\"\"\n",
    "\n",
    "import re\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.layers import Embedding, Dropout, Conv1D, MaxPool1D, GRU, LSTM, Dense\n",
    "\n",
    "def reviewWords(review, method):\n",
    "    data_train_Exclude_tags = re.sub(r'<[^<>]+>', \" \", review)      # Excluding the html tags\n",
    "    data_train_num = re.sub(r'[0-9]+', 'number', data_train_Exclude_tags)  # Converting numbers to \"NUMBER\"\n",
    "    data_train_lower = data_train_num.lower()              # Converting to lower case.\n",
    "    data_train_no_punctuation = re.sub(r\"[^a-zA-Z]\", \" \", data_train_lower )\n",
    "       \n",
    "    # using porter stemming.\n",
    "    # https://pythonprogramming.net/stemming-nltk-tutorial/\n",
    "    # https://github.com/MohammadWasil/Coursera-Machine-Learning-Python/blob/master/CSR%20ML/WEEK%237/Machine%20Learning%20Assignment%236/Python/processEmail.py\n",
    "    if method == \"Porter Stemming\":\n",
    "        #print(\"Processing dataset with porter stemming...\")\n",
    "        stemmedWords = [ps.stem(word) for word in re.findall(r\"\\w+\", data_train_no_punctuation)]\n",
    "        return(\" \".join(stemmedWords))         \n",
    "        \n",
    "    # ussing stop words.\n",
    "    # After using stop words, training accuracy increases, but testing accuracy decreases in Kaggle.\n",
    "    # This method might overfit the training data.\n",
    "    if method == \"Stop Words\":\n",
    "        #print(\"Processing dataset with stop words...\")\n",
    "        data_train_split = data_train_no_punctuation.split()            # Splitting into individual words.\n",
    "        stopWords = set(stopwords.words(\"english\") )\n",
    "        meaningful_words = [w for w in data_train_split if not w in stopWords]     # Removing stop words.\n",
    "        return( \" \".join( meaningful_words ))  \n",
    "    \n",
    "    if method == \"Nothing\":\n",
    "        #print(\"Processing dataset without porter stemming and stop words...\")\n",
    "        return data_train_no_punctuation       \n",
    "    \n",
    "def training_Validation_Data(cleanWords, data_train):\n",
    "    \n",
    "    X = cleanWords\n",
    "    y = data_train[\"sentiment\"]\n",
    "    \n",
    "    test_start_index = int(data_train.shape[0] * .8)\n",
    "    \n",
    "    x_train = X[0:test_start_index]\n",
    "    y_train = y[0:test_start_index]\n",
    "    x_val = X[test_start_index:]\n",
    "    y_val = y[test_start_index:]\n",
    "\n",
    "    return x_train, y_train, x_val, y_val\n",
    "\n",
    "# Reading the Data\n",
    "data_train = pd.read_csv(\".../labeledTrainData.tsv\", delimiter = \"\\t\")\n",
    "data_test = pd.read_csv(\".../testData.tsv\", delimiter = \"\\t\")\n",
    "\n",
    "# Input the value, whether you want to include porter stemming, stopwords.\n",
    "print(\"Input 'Porter Stemming' for porter stemming, 'Stop Words' for stop words, or anywords for Neither of them: \")\n",
    "preprocessingInput = input(\"Do you want to include porter stemming or stop word?\\n\")\n",
    "\n",
    "if preprocessingInput == \"Porter Stemming\":\n",
    "    method = \"Porter Stemming\"\n",
    "    ps = PorterStemmer()        # instantiating a class instance.\n",
    "    \n",
    "elif preprocessingInput == \"Stop Words\":\n",
    "    method = \"Stop Words\"\n",
    "    \n",
    "else:\n",
    "    method = \"Nothing\"\n",
    "    \n",
    "# Input the value, whether you want to run the model on LSTM RNN or GRU RNN.\n",
    "print(\"Input 'LSTM' for LSTM RNN, 'GRU' for GRU RNN \")\n",
    "modelInput= input(\"Do you want to compile the model using LSTM RNN or GRU RNN?\\n\")\n",
    "\n",
    "if modelInput == \"LSTM\":\n",
    "    lstm = True\n",
    "else:\n",
    "    lstm = False\n",
    "\n",
    "\n",
    "# Let's process all the reviews together of train data.\n",
    "\n",
    "cleanWords = []\n",
    "for i in range(data_train['review'].size):\n",
    "    cleanWords.append( reviewWords( data_train[\"review\"][i], method ))\n",
    "print(\"---Review Processing Done!---\\n\")\n",
    "\n",
    "# Splitting the data into tran and validation\n",
    "x_train, y_train, x_val, y_val = training_Validation_Data(cleanWords, data_train)\n",
    "\n",
    "# There is a data leakage in test set.\n",
    "data_test[\"sentiment\"] = data_test[\"id\"].map(lambda x: 1 if int(x.strip('\"').split(\"_\")[1]) >= 5 else 0)\n",
    "y_test = data_test[\"sentiment\"]\n",
    "\n",
    "# Processing text dataset reviews.\n",
    "testcleanWords = []\n",
    "for i in range(data_train['review'].size):\n",
    "    testcleanWords.append( reviewWords( data_test[\"review\"][i], method ))\n",
    "print(\"---Test Review Processing Done!---\\n\")\n",
    "\n",
    "# Generate the text sequence for RNN model\n",
    "np.random.seed(1000)\n",
    "num_most_freq_words_to_include = 5000\n",
    "MAX_REVIEW_LENGTH_FOR_KERAS_RNN = 500           # Input for keras.\n",
    "embedding_vector_length = 32\n",
    "\n",
    "all_review_list = x_train + x_val\n",
    "\n",
    "tokenizer = Tokenizer(num_words = num_most_freq_words_to_include)\n",
    "tokenizer.fit_on_texts(all_review_list)\n",
    "\n",
    "#tokenisingtrain data\n",
    "train_reviews_tokenized = tokenizer.texts_to_sequences(x_train)      \n",
    "x_train = pad_sequences(train_reviews_tokenized, maxlen = MAX_REVIEW_LENGTH_FOR_KERAS_RNN)          # 20,000 x 500\n",
    "\n",
    "#tokenising validation data\n",
    "val_review_tokenized = tokenizer.texts_to_sequences(x_val)\n",
    "x_val = pad_sequences(val_review_tokenized, maxlen = MAX_REVIEW_LENGTH_FOR_KERAS_RNN)               # 5000 X 500 \n",
    "\n",
    "#tokenising Test data\n",
    "test_review_tokenized = tokenizer.texts_to_sequences(testcleanWords)\n",
    "x_test = pad_sequences(test_review_tokenized, maxlen = MAX_REVIEW_LENGTH_FOR_KERAS_RNN)               # 5000 X 500 \n",
    "\n",
    "# Save the tokenizer, so that we can use this tokenizer whenever we need to predict any reviews.\n",
    "with open('tokenizer.pickle', 'wb') as handle:\n",
    "    pickle.dump(tokenizer, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "def RNNModel(lstm = False):\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(input_dim = num_most_freq_words_to_include, \n",
    "                                output_dim = embedding_vector_length,\n",
    "                                input_length = MAX_REVIEW_LENGTH_FOR_KERAS_RNN))\n",
    "    \n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Conv1D(filters = 32, kernel_size = 3, padding = 'same', activation = 'relu'))\n",
    "    model.add(MaxPool1D(pool_size = 2))\n",
    "    if lstm == True:\n",
    "        model.add(LSTM(100))\n",
    "    else:\n",
    "        model.add(GRU(100))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(1, activation = 'sigmoid'))             \n",
    "    model.compile(loss = 'binary_crossentropy', optimizer = 'adam', metrics = ['accuracy'])\n",
    "    \n",
    "    return model\n",
    "\n",
    "themodel = RNNModel(lstm)\n",
    "themodel.summary()\n",
    "themodel.fit(x_train, y_train, batch_size=64, epochs=3, validation_data=[x_val, y_val])\n",
    "\n",
    "# LSTM\n",
    "# training accuracy - 91.7 - without using stop words.LSTM\n",
    "# training accuracy - 92.59 - with using stop words.LSTM\n",
    "# training accuracy - 91.57 - with using porter stemming(No Stop words).LSTM\n",
    "# GRU\n",
    "# training accuracy - 91.93 - without using stopwords, porter stemming. -GRU \n",
    "# training accuracy - 92.76 - with using stop words.GRU\n",
    "# training accuracy - 92.07 - with using porter stemming.GRU\n",
    "\n",
    "# Creating file name for saving the model.\n",
    "if lstm == True:\n",
    "    modelSelected = \"LSTM\"\n",
    "else:\n",
    "    modelSelected = \"GRU\"\n",
    "fileName = \"RNN \" + modelSelected + \" model\" + method + \".h5\"\n",
    "\n",
    "# Saving the model for future reference.\n",
    "themodel.save(fileName)\n",
    "\n",
    "# Prediction.\n",
    "ytest_prediction = themodel.predict(x_test)\n",
    "\n",
    "from sklearn.metrics import  roc_auc_score\n",
    "print(\"The roc AUC socre for GRU(using porter stemming) model is : %.4f.\" %roc_auc_score(y_test, ytest_prediction)) \n",
    "\n",
    "# LSTM\n",
    "# 94.71-without using stop words.LSTM\n",
    "# 94.23-with using stop words.LSTM\n",
    "# 94.65-without using stop words, only using porter stemming.LSTM\n",
    "# GRU\n",
    "# 94.52-without using stop words, porter stemming.-GRU\n",
    "# 94.12-with using stop words.GRU\n",
    "# 94.20-with using portrestemming(No stop words).GRU\n",
    "\n",
    "# Creating csv file for \n",
    "# Changing the shape of ytest_prediction to 1-Dimensional\n",
    "ytest_prediction = np.array(ytest_prediction).reshape((25000, ))\n",
    "for i in range(len(ytest_prediction)):\n",
    "    ytest_prediction[i] = round(ytest_prediction[i])\n",
    "ytest_prediction = ytest_prediction.astype(int)\n",
    "\n",
    "# Copy the predicted values to pandas dataframe with an id column, and a sentiment column.\n",
    "output = pd.DataFrame(data = {\"id\": data_test[\"id\"], \"sentiment\": ytest_prediction} )\n",
    "\n",
    "outputName = \"Predicted RNN \" + modelSelected + \" model\" + method + \".csv\"\n",
    "output.to_csv(outputName, index = False, quoting = 3 )\n",
    "\n",
    "# Score on kaggle comes out to be 0.87240 (Without usng stopwords, without using porter stemming.)-lstm\n",
    "# Score on kaggle comes out to be 0.86964 (With using stopwords.)-lstm\n",
    "# Score on kaggle comes out to be 0.87896 (Without using stopwords, using Porter Stemming.)-lstm\n",
    "# next, try training it on GRU Recurrent Neural Network.\n",
    "# Score on kaggle comes out to be 0.87444 (Without using stopwords, without using porter stemming.)-GRU\n",
    "# Score on kaggle comes out to be 0.86768 (With using stopwords.)-GRU\n",
    "# Score on kaggle comes out to be 0.86944 (Wiith using porter stemming.)-GRU\n",
    "\n",
    "cm = confusion_matrix(y_test, ytest_prediction)\n",
    "print(cm)\n",
    "\n",
    "### Confusion Matrix ###\n",
    "\n",
    "# GRU without stop words, without porter stemming\n",
    "# Confusion matrix.\n",
    "# [ [10715  1785]\n",
    "#   [ 1358 11142] ]\n",
    "# misclassifying 3,143.\n",
    "\n",
    "# GRU with using stop words, no porter stemming.\n",
    "# [[10971  1529]\n",
    "#  [ 1779 10721]]\n",
    "# misclassifying 3,308\n",
    "\n",
    "# It seems that, when we used stop words, model overfit in the training set.\n",
    "# When given new examples, it was not able to generalize well.\n",
    "# i.e. the testing accuracy decreases.\n",
    "\n",
    "# GRU without using stop words, only porter stemming\n",
    "# [[10653  1847]\n",
    "#  [ 1417 11083]]\n",
    "# misclassifying 3,264\n",
    "\n",
    "# LSTM without stop words, without porter stemming.\n",
    "# [[11465  1035]\n",
    "#  [ 2261 10239]]\n",
    "# misclassifying 3,296\n",
    "\n",
    "#######################"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
